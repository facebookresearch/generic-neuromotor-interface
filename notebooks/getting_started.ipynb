{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7ea5b86f-8e52-4d44-86d0-fd9e9596f79f",
      "metadata": {},
      "source": [
        "# Getting Started\n",
        "\n",
        "This notebook showcases basic functionality of the code base.\n",
        "\n",
        "Here, we load the metadata, an example dataset, and run inference using a pre-trained model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9151a71-0405-4c56-8f08-5b521d65b7b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92da9ca9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from tempfile import gettempdir\n",
        "\n",
        "# DATA_DOWNLOAD_DIR = Path.home()\n",
        "\n",
        "DATA_DOWNLOAD_DIR = gettempdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffb00cdf-5cc6-42f2-b56c-10dae97f7215",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "repo_path = Path(\"/src/platform/generic_neuromotor_interface/\")\n",
        "assert os.path.exists(repo_path)\n",
        "\n",
        "print(\"Installing package...\")\n",
        "!pip install -e {repo_path} -qqq\n",
        "\n",
        "print(\"Please restart kernel if first install!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b198034e-1b38-4524-9161-b408e5740cb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import generic_neuromotor_interface"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68021559",
      "metadata": {},
      "source": [
        "## Download Dataset Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "582fc209",
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd {DATA_DOWNLOAD_DIR} && wget https://fb-ctrl-oss.s3.amazonaws.com/emg2pose/emg2pose_metadata.csv -O emg2pose_metadata.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e78b0ad1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "metadata_df = pd.read_csv(Path(DATA_DOWNLOAD_DIR) / \"emg2pose_metadata.csv\")\n",
        "metadata_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c68f4199",
      "metadata": {},
      "source": [
        "## Download a Smaller (~600 MiB) Version of the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ce9b80b",
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd {DATA_DOWNLOAD_DIR} && wget \"https://fb-ctrl-oss.s3.amazonaws.com/emg2pose/emg2pose_dataset_mini.tar\" -O emg2pose_dataset_mini.tar\n",
        "\n",
        "# Unpack the tar to ~/emg2pose_dataset_mini\n",
        "!cd {DATA_DOWNLOAD_DIR} && tar -xvf emg2pose_dataset_mini.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a720e17e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "sessions = sorted(glob.glob(os.path.join(DATA_DOWNLOAD_DIR, \"emg2pose_dataset_mini/*.hdf5\")))\n",
        "sessions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0f2f73d",
      "metadata": {},
      "source": [
        "## Let's Look at a Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef869193",
      "metadata": {},
      "outputs": [],
      "source": [
        "from generic_neuromotor_interface.data import Emg2PoseSessionData\n",
        "\n",
        "session = sessions[15]\n",
        "data = Emg2PoseSessionData(hdf5_path=session)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee528ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(data.fields)\n",
        "print()\n",
        "\n",
        "print(f\"{'emg shape: ':<20} {data['emg'].shape}\")\n",
        "print(f\"{'joint_angles shape: ':<20} {data['joint_angles'].shape}\")\n",
        "print(f\"{'time shape: ':<20} {data['time'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e63b05",
      "metadata": {},
      "outputs": [],
      "source": [
        "metadata_df[metadata_df[\"filename\"] == data.metadata[\"filename\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df732445",
      "metadata": {},
      "source": [
        "## Let's Load a Checkpoint and Generate some Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce8f4bf4",
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd {DATA_DOWNLOAD_DIR} \\\n",
        "&& wget \"https://fb-ctrl-oss.s3.amazonaws.com/emg2pose/emg2pose_model_checkpoints.tar.gz\" -O emg2pose_model_checkpoints.tar.gz && \\\n",
        "tar -xvzf emg2pose_model_checkpoints.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "364ac6ac-d025-4f87-9903-0ff963b9a99f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from generic_neuromotor_interface.utils import generate_hydra_config_from_overrides\n",
        "\n",
        "config = generate_hydra_config_from_overrides(\n",
        "    overrides=[\n",
        "        \"experiment=tracking_vemg2pose\",\n",
        "        f\"checkpoint={DATA_DOWNLOAD_DIR}/emg2pose_model_checkpoints/regression_vemg2pose.ckpt\"\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3c605e9-7bdf-4f58-93c4-25d07d06d9db",
      "metadata": {},
      "outputs": [],
      "source": [
        "from generic_neuromotor_interface.lightning import Emg2PoseModule\n",
        "\n",
        "module = Emg2PoseModule.load_from_checkpoint(\n",
        "    config.checkpoint,\n",
        "    network=config.network,\n",
        "    optimizer=config.optimizer,\n",
        "    lr_scheduler=config.lr_scheduler,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d2f80ce-2fe3-4751-b76b-0278cb4b440f",
      "metadata": {},
      "outputs": [],
      "source": [
        "session = data\n",
        "start_idx = 0\n",
        "stop_idx = 10_000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f778327-50d2-4358-8ba6-00ff3d996b0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "session_window = session[start_idx:stop_idx]\n",
        "\n",
        "# no_ik_failure is not a field so we slice separately\n",
        "no_ik_failure_window = session.no_ik_failure[start_idx:stop_idx]\n",
        "\n",
        "batch = {\n",
        "    \"emg\": torch.Tensor([session_window[\"emg\"].T]),  # BCT\n",
        "    \"joint_angles\": torch.Tensor([session_window[\"joint_angles\"].T]),  # BCT\n",
        "    \"no_ik_failure\": torch.Tensor([no_ik_failure_window]),  # BT\n",
        "}\n",
        "\n",
        "preds, joint_angles, no_ik_failure = module.forward(batch)\n",
        "\n",
        "# Algorithms that use the initial state for ground truth will do poorly\n",
        "# when the first joint angles are missing!\n",
        "if (joint_angles[:, 0] == 0).all():\n",
        "    print(\n",
        "        \"Warning! Ground truth not available at first time step!\"\n",
        "    )\n",
        "\n",
        "# BCT --> TC (as numpy)\n",
        "preds = preds[0].T.detach().numpy()\n",
        "joint_angles = joint_angles[0].T.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2cf1cdd-585f-439f-a17d-37c2ed055bcf",
      "metadata": {},
      "outputs": [],
      "source": [
        "preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f16e29cc-1a96-4c57-8f35-800b742c2f0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "joint_angles.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55167a87",
      "metadata": {},
      "source": [
        "### Compare the Ground Truth and Predictions Side-by-Side"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98f56de8-3207-46d8-b55f-6328254c7751",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "N_COLS = 2\n",
        "N_ROWS = 10\n",
        "\n",
        "fig, axs = plt.subplots(N_ROWS, N_COLS, figsize=(4*N_COLS, 2*N_ROWS))\n",
        "\n",
        "axs_flattened = axs.flatten()\n",
        "for i, ax in enumerate(axs_flattened):\n",
        "    ax.set_title(f\"Joint Angle {i}\")\n",
        "    ax.plot(joint_angles[:, i], label=\"gt\")\n",
        "    ax.plot(preds[:, i], label=\"pred\")\n",
        "\n",
        "    ax.legend()\n",
        "\n",
        "fig.suptitle(\"Predicted vs. Ground Truth Joint Angles\")\n",
        "\n",
        "plt.tight_layout()\n",
        "fig.subplots_adjust(top=0.95)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9dbeaf0-8d62-455d-8bee-86bce0b899a2",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "fileHeader": "",
    "fileUid": "b703cb6f-16a4-489d-b01f-e059bf9420ae",
    "isAdHoc": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {},
        "version_major": 2,
        "version_minor": 0
      }
    }
  }
}
