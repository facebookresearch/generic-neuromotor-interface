{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dc4ca906-960d-4103-b8b2-14fe67611352",
      "metadata": {},
      "source": [
        "# Discrete gesture decoder evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28e59640-652c-46ee-bc15-2bd4abbe9105",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from pytorch_lightning import Trainer\n",
        "from hydra import initialize, compose\n",
        "from hydra.utils import instantiate\n",
        "import omegaconf\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from generic_neuromotor_interface.cler import GestureType\n",
        "from generic_neuromotor_interface.cler import compute_cler\n",
        "\n",
        "from generic_neuromotor_interface.scripts.download_data import download_data\n",
        "from generic_neuromotor_interface.scripts.download_models import download_models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91422cd0-6246-46a0-8131-b9469c9c7d74",
      "metadata": {},
      "source": [
        "## Establish paths to data and model files\n",
        "\n",
        "Before running this notebook you must make sure to download the data and model checkpoint as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e0dcfb6-0315-4321-97bd-2fab2aa5d821",
      "metadata": {},
      "outputs": [],
      "source": [
        "EMG_DATA_DIR = \"~/emg_data/\"  # path to EMG data\n",
        "MODELS_DIR = \"~/emg_models/\"  # path to model files\n",
        "\n",
        "TASK = \"discrete_gestures\"\n",
        "DATASET_TYPE = \"small_subset\"  # 'small_subset' or 'full_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## uncomment to download if you haven't already\n",
        "\n",
        "# download_data(TASK, DATASET_TYPE, EMG_DATA_DIR)\n",
        "# download_models(TASK, MODELS_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09138984-111a-435e-b7b4-90c446d10309",
      "metadata": {},
      "source": [
        "## Load model checkpoint and config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d16eb69b-2720-4e74-a5e9-a49e5e01ce5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Retrieve model checkpoint\"\"\"\n",
        "\n",
        "model_ckpt_path = os.path.join(os.path.expanduser(MODELS_DIR), \"discrete_gestures\", \"model_checkpoint.ckpt\")\n",
        "\n",
        "if not os.path.exists(model_ckpt_path):\n",
        "    raise FileNotFoundError(f\"The model checkpoint path does not exist: {model_ckpt_path}\")\n",
        "\n",
        "model_ckpt = torch.load(\n",
        "    model_ckpt_path,\n",
        "    map_location=torch.device(\"cpu\"),\n",
        "    weights_only=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df1f36ae-f1f3-4488-846a-70e969a95cf1",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Retrieve the config\"\"\"\n",
        "\n",
        "config_path = os.path.join(os.path.expanduser(MODELS_DIR), \"discrete_gestures\")\n",
        "\n",
        "if not os.path.exists(config_path):\n",
        "    raise FileNotFoundError(f\"The config path does not exist: {config_path}\")\n",
        "\n",
        "with initialize(config_path=os.path.relpath(config_path), version_base=\"1.1\"):\n",
        "    cfg = compose(config_name=\"model_config\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "765e9500-1ca2-4392-b268-515159db4a52",
      "metadata": {},
      "source": [
        "## Instantiate model and data module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dda10e70-6ebf-40ab-b0e4-563bc84d7467",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Load the model\"\"\"\n",
        "\n",
        "# Instantiate model\n",
        "model = instantiate(cfg.lightning_module)\n",
        "\n",
        "# Load the checkpoint state_dict\n",
        "model.load_state_dict(model_ckpt[\"state_dict\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65f784c1-bbbf-4832-a1ed-6d01a9a9e6e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Assemble the data module\"\"\"\n",
        "\n",
        "data_path = os.path.expanduser(EMG_DATA_DIR)\n",
        "\n",
        "if not os.path.exists(data_path):\n",
        "    raise FileNotFoundError(f\"The EMG data path does not exist: {data_path}\")\n",
        "\n",
        "# Assemble DataModule config\n",
        "datamodule_cfg = omegaconf.OmegaConf.to_container(cfg.data_module)\n",
        "datamodule_cfg[\"data_location\"] = EMG_DATA_DIR\n",
        "if \"from_csv\" in datamodule_cfg[\"data_split\"][\"_target_\"]:\n",
        "    datamodule_cfg[\"data_split\"][\"csv_filename\"] = os.path.join(data_path, \"discrete_gestures_corpus.csv\")\n",
        "\n",
        "# Instantiate DataModule\n",
        "datamodule = instantiate(datamodule_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35e49cd0-367f-4ceb-a29d-5ae3e5552376",
      "metadata": {},
      "source": [
        "## Run inference on one test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7486a86d-7471-42b8-9905-f9ed68c8f334",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Grab one test dataset\"\"\"\n",
        "\n",
        "test_dataset = datamodule._make_dataset({\"discrete_gestures_user_002_dataset_000\": None}, \"test\")  # from discrete_gestures_mini_split.yaml\n",
        "sample = test_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "debef9e4-0154-4653-9d23-f5907c54381f",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Run inference\"\"\"\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# unpack sample\n",
        "emg = sample[\"emg\"]\n",
        "emg_times = sample[\"timestamps\"]\n",
        "labels = sample[\"prompts\"]\n",
        "\n",
        "# compute model outputs\n",
        "with torch.no_grad():\n",
        "    logits = model(emg.unsqueeze(0))\n",
        "\n",
        "logits = logits[0]\n",
        "\n",
        "# convert logits to probabilities\n",
        "probs = torch.nn.Sigmoid()(logits)\n",
        "\n",
        "# get timestamps associated with each predicted probability\n",
        "prob_times = emg_times[model.network.left_context::model.network.stride]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5f20442-b685-4cf5-bfab-472def81f5e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Evaluate CLER\"\"\"\n",
        "\n",
        "cler = compute_cler(probs, prob_times, labels)\n",
        "\n",
        "print(\"CLER on this dataset:\", cler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7244f5ee-e923-4926-b742-c1f3107d9274",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Plot predictions and targets\"\"\"\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 5), sharex=True, sharey=False)\n",
        "\n",
        "t0 = emg_times[0]\n",
        "\n",
        "# plot EMG\n",
        "ax = axes[0]\n",
        "spacing = 200\n",
        "for channel_index, channel_data in enumerate(emg):\n",
        "    ax.plot(\n",
        "        emg_times - t0,\n",
        "        channel_data + channel_index * spacing,\n",
        "        linewidth=1,\n",
        "        color=\"0.7\",\n",
        "    )\n",
        "\n",
        "ax.set_ylim([-spacing, len(emg) * spacing])\n",
        "ax.set_yticks([])\n",
        "\n",
        "sns.despine(ax=ax, left=True)\n",
        "\n",
        "# labels\n",
        "ax = axes[1]\n",
        "for gesture in GestureType:\n",
        "    prob_index = gesture.value\n",
        "    ax.plot(\n",
        "        prob_times - t0,\n",
        "        probs[prob_index] + prob_index,\n",
        "        linewidth=1,\n",
        "        label=gesture.name\n",
        "    )\n",
        "\n",
        "ax.set_yticks([])\n",
        "\n",
        "sns.despine(ax=ax, left=True)\n",
        "\n",
        "legends, handles = ax.get_legend_handles_labels()\n",
        "ax.legend(\n",
        "    legends[::-1],\n",
        "    handles[::-1],\n",
        "    loc=\"upper left\",\n",
        "    ncols=1,\n",
        "    bbox_to_anchor=(1.0, 1.0),\n",
        "    frameon=False\n",
        ")\n",
        "\n",
        "ax.set_xlim([352, 357])\n",
        "\n",
        "axes[0].set_ylabel(\"EMG\\n(normalized)\")\n",
        "axes[1].set_ylabel(\"predicted gesture\\nprobability\")\n",
        "axes[1].set_xlabel(\"time\\n(sec)\")\n",
        "\n",
        "\n",
        "tmin, tmax = ax.get_xlim()\n",
        "_, ymax = axes[0].get_ylim()\n",
        "\n",
        "labels_in_window = False\n",
        "\n",
        "for label in labels.to_dict(orient=\"records\"):\n",
        "    gesture_name = label[\"name\"]\n",
        "    t = label[\"time\"] - t0\n",
        "    if (t > tmin) and (t < tmax):\n",
        "        labels_in_window = True\n",
        "        lines = axes[0].axvline(t, color=\"k\")\n",
        "        axes[0].text(\n",
        "            t - 0.075,\n",
        "            ymax + 200,\n",
        "            gesture_name,\n",
        "            rotation=\"vertical\",\n",
        "            va=\"top\",\n",
        "            ha=\"left\"\n",
        "        )\n",
        "\n",
        "if labels_in_window:\n",
        "    axes[0].legend(\n",
        "        [lines],\n",
        "        [\"ground truth labels\"],\n",
        "        loc=\"upper left\",\n",
        "        ncols=1,\n",
        "        bbox_to_anchor=(1.0, 1.0),\n",
        "        frameon=False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b3c9f4b-f9db-4883-bbf2-281ace7be29a",
      "metadata": {},
      "source": [
        "## Evaluate full test set\n",
        "\n",
        "Note that this requires you to have downloaded the full dataset (`full_data` instead of `small_subset`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## uncomment to download if you haven't already\n",
        "\n",
        "# download_data(TASK, \"full_data\", EMG_DATA_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e71dfaab-7a79-4136-a416-17610198e869",
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = Trainer()\n",
        "test_results = trainer.test(model=model, datamodule=datamodule)"
      ]
    }
  ],
  "metadata": {
    "fileHeader": "",
    "fileUid": "237638cf-2c2e-485a-acdd-c6ce368a3c9d",
    "isAdHoc": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  }
}
