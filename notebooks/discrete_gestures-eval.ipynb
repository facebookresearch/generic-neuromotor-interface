{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4ca906-960d-4103-b8b2-14fe67611352",
   "metadata": {},
   "source": [
    "# Discrete gesture decoder evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e59640-652c-46ee-bc15-2bd4abbe9105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from generic_neuromotor_interface.cler import GestureType, compute_cler\n",
    "from generic_neuromotor_interface.data import make_dataset\n",
    "\n",
    "TASK_NAME = \"discrete_gestures\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91422cd0-6246-46a0-8131-b9469c9c7d74",
   "metadata": {},
   "source": [
    "## Establish paths to data and model files\n",
    "\n",
    "Before running this notebook you must make sure to download the data and model checkpoint as follows:\n",
    "```\n",
    "cd ~/generic-neuromotor-interface-data\n",
    "\n",
    "./download_data.sh discrete_gestures small_subset <EMG_DATA_DIR>  # or full_data instead of small_subset\n",
    "\n",
    "./download_models.sh discrete_gestures <MODELS_DIR>\n",
    "```\n",
    "where `<EMG_DATA_DIR>` and `<MODELS_DIR>` should match the directory specified by the `EMG_DATA_DIR` and `MODELS_DIR` variables defined in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0dcfb6-0315-4321-97bd-2fab2aa5d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMG_DATA_DIR = \"~/emg_data/\"  # path to EMG data\n",
    "MODELS_DIR = \"~/emg_models/\"  # path to model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bde32f-7f8a-45f7-86f4-085f39c5020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.expanduser(EMG_DATA_DIR)):\n",
    "    raise FileNotFoundError(f\"The EMG data path does not exist: {EMG_DATA_DIR}\")\n",
    "\n",
    "if not os.path.exists(os.path.expanduser(MODELS_DIR)):\n",
    "    raise FileNotFoundError(f\"The models path does not exist: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a5396-227e-482c-a269-101995844d5c",
   "metadata": {},
   "source": [
    "## Load model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990839d8-1d29-4913-bdf2-a82c0c49e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load model config\"\"\"\n",
    "\n",
    "config_path = os.path.join(os.path.expanduser(MODELS_DIR), TASK_NAME, \"model_config.yaml\")\n",
    "config = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9fda8-5305-4715-af71-4e7e0afbeba6",
   "metadata": {},
   "source": [
    "## Load model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b436fe-d5cf-4416-b75b-aaeb4d288216",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load model checkpoint\"\"\"\n",
    "\n",
    "model_ckpt_path = os.path.join(\n",
    "    os.path.expanduser(MODELS_DIR),\n",
    "    TASK_NAME,\n",
    "    \"model_checkpoint.ckpt\"\n",
    ")\n",
    "model = instantiate(config.lightning_module)\n",
    "model = model.load_from_checkpoint(\n",
    "    model_ckpt_path,\n",
    "    map_location=torch.device(\"cpu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765e9500-1ca2-4392-b268-515159db4a52",
   "metadata": {},
   "source": [
    "## Instantiate data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f784c1-bbbf-4832-a1ed-6d01a9a9e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Assemble the data module\"\"\"\n",
    "\n",
    "# Update DataModule config with data path\n",
    "config[\"data_module\"][\"data_location\"] = os.path.expanduser(EMG_DATA_DIR)\n",
    "if \"from_csv\" in config[\"data_module\"][\"data_split\"][\"_target_\"]:\n",
    "    config[\"data_module\"][\"data_split\"][\"csv_filename\"] = os.path.join(\n",
    "        os.path.expanduser(EMG_DATA_DIR),\n",
    "        f\"{TASK_NAME}_corpus.csv\"\n",
    "    )\n",
    "\n",
    "datamodule = instantiate(config[\"data_module\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e49cd0-367f-4ceb-a29d-5ae3e5552376",
   "metadata": {},
   "source": [
    "## Run inference on one test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7486a86d-7471-42b8-9905-f9ed68c8f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Grab one test dataset\"\"\"\n",
    "\n",
    "test_dataset = make_dataset(\n",
    "    datamodule.data_location,\n",
    "    partition_dict={\"discrete_gestures_user_002_dataset_000\": None},  # from discrete_gestures_mini_split.yaml\n",
    "    transform=datamodule.transform,\n",
    "    emg_augmentation=None,\n",
    "    window_length=None,\n",
    "    stride=None,\n",
    "    jitter=False,\n",
    ")\n",
    "\n",
    "sample = test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debef9e4-0154-4653-9d23-f5907c54381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run inference\"\"\"\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# unpack sample\n",
    "emg = sample[\"emg\"]\n",
    "emg_times = sample[\"timestamps\"]\n",
    "labels = sample[\"prompts\"]\n",
    "\n",
    "# compute model outputs\n",
    "with torch.no_grad():\n",
    "    logits = model(emg.unsqueeze(0))\n",
    "\n",
    "logits = logits[0]\n",
    "    \n",
    "# convert logits to probabilities\n",
    "probs = torch.nn.Sigmoid()(logits)\n",
    "\n",
    "# get timestamps associated with each predicted probability\n",
    "prob_times = emg_times[model.network.left_context::model.network.stride]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f20442-b685-4cf5-bfab-472def81f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate CLER\"\"\"\n",
    "\n",
    "cler = compute_cler(probs, prob_times, labels)\n",
    "\n",
    "print(\"CLER on this dataset:\", cler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7244f5ee-e923-4926-b742-c1f3107d9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot predictions and targets\"\"\"\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 5), sharex=True, sharey=False)\n",
    "\n",
    "t0 = emg_times[0]\n",
    "\n",
    "# plot EMG\n",
    "ax = axes[0]\n",
    "spacing = 200\n",
    "for channel_index, channel_data in enumerate(emg):\n",
    "    ax.plot(\n",
    "        emg_times - t0,\n",
    "        channel_data + channel_index * spacing,\n",
    "        linewidth=1,\n",
    "        color=\"0.7\",\n",
    "    )\n",
    "\n",
    "ax.set_ylim([-spacing, len(emg) * spacing])\n",
    "ax.set_yticks([])\n",
    "\n",
    "sns.despine(ax=ax, left=True)\n",
    "    \n",
    "# labels\n",
    "ax = axes[1]\n",
    "for gesture in GestureType:\n",
    "    prob_index = gesture.value\n",
    "    ax.plot(\n",
    "        prob_times - t0,\n",
    "        probs[prob_index] + prob_index,\n",
    "        linewidth=1,\n",
    "        label=gesture.name\n",
    "    )\n",
    "\n",
    "ax.set_yticks([])\n",
    "\n",
    "sns.despine(ax=ax, left=True)\n",
    "\n",
    "legends, handles = ax.get_legend_handles_labels()\n",
    "ax.legend(\n",
    "    legends[::-1],\n",
    "    handles[::-1],\n",
    "    loc=\"upper left\",\n",
    "    ncols=1,\n",
    "    bbox_to_anchor=(1.0, 1.0),\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "ax.set_xlim([352, 357])\n",
    "\n",
    "axes[0].set_ylabel(\"EMG\\n(normalized)\")\n",
    "axes[1].set_ylabel(\"predicted gesture\\nprobability\")\n",
    "axes[1].set_xlabel(\"time\\n(sec)\")\n",
    "\n",
    "\n",
    "tmin, tmax = ax.get_xlim()\n",
    "_, ymax = axes[0].get_ylim()\n",
    "\n",
    "labels_in_window = False\n",
    "\n",
    "for label in labels.to_dict(orient=\"records\"):\n",
    "    gesture_name = label[\"name\"]\n",
    "    t = label[\"time\"] - t0\n",
    "    if (t > tmin) and (t < tmax):\n",
    "        labels_in_window = True\n",
    "        lines = axes[0].axvline(t, color=\"k\")\n",
    "        axes[0].text(\n",
    "            t - 0.075,\n",
    "            ymax + 200,\n",
    "            gesture_name,\n",
    "            rotation=\"vertical\",\n",
    "            va=\"top\",\n",
    "            ha=\"left\"\n",
    "        )\n",
    "\n",
    "if labels_in_window:\n",
    "    axes[0].legend(\n",
    "        [lines],\n",
    "        [\"ground truth labels\"],\n",
    "        loc=\"upper left\",\n",
    "        ncols=1,\n",
    "        bbox_to_anchor=(1.0, 1.0),\n",
    "        frameon=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c9f4b-f9db-4883-bbf2-281ace7be29a",
   "metadata": {},
   "source": [
    "## Evaluate full test set\n",
    "\n",
    "Note that this requires you to have downloaded the full dataset (`full_data` instead of `small_subset`) when invoking `./download_data.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71dfaab-7a79-4136-a416-17610198e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(accelerator=\"cpu\")\n",
    "test_results = trainer.test(model=model, datamodule=datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
