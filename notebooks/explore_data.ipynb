{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a40d1e8-d1f5-41f4-b981-c299324167ee",
   "metadata": {},
   "source": [
    "Loading and Plotting surface EMG Data\n",
    "====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ee8e8-be80-4935-b9a6-8ebd2207f54a",
   "metadata": {},
   "source": [
    "Here we show how to load and visualize EMG data collected at the wrist as described in the paper [\"A generic noninvasive neuromotor interface for human-computer interaction\"](https://www.biorxiv.org/content/10.1101/2024.02.23.581779v1.full.pdf). We will show examples from each of the three tasks described in the paper: `discrete_gestures`, `handwriting`, and `wrist`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3706b1-918f-4e5e-901b-4ae71a7b20fc",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e34fbef-3068-4596-b5cb-ed03deb81860",
   "metadata": {},
   "source": [
    "First download the data, as described in the `README`. If necessary, set the `DATA_FOLDER` below to the location of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564064b6-773e-4be6-82b9-430d87d53289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generic_neuromotor_interface.explore_data.plot import plot_emg, plot_wrist\n",
    "from generic_neuromotor_interface.explore_data.load import load_data\n",
    "from generic_neuromotor_interface.constants import Task\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "DATA_FOLDER = \"~/emg_data/\"\n",
    "\n",
    "def get_task_dataset_paths(task: Task):\n",
    "    \"\"\"Get full paths to all datasets for a given task.\"\"\"\n",
    "    folder = os.path.expanduser(DATA_FOLDER)\n",
    "    datasets = glob.glob(os.path.join(folder, '*.hdf5'))\n",
    "    return [d for d in datasets if task in d]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6750dc-2aa1-4c27-be9f-4c225bb18487",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646774fd-7c8a-429b-bba5-522543fb19b8",
   "metadata": {},
   "source": [
    "Next we'll select one of the `discrete_gestures` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a856c5-5544-43f8-9862-376a0c006dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = get_task_dataset_paths(\"discrete_gestures\")[0]\n",
    "print(\"Selected file:\", os.path.basename(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ca992d-90fe-4499-a785-cf8522adf3ca",
   "metadata": {},
   "source": [
    "We'll load the file using the `load_data` utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a229cee-de3d-4c0b-958b-8b3df384c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(file)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c878e4a-1783-4844-afb0-f13e45d1ee21",
   "metadata": {},
   "source": [
    "The file contains EMG, timestamps, a task identifier, a `prompts` dataframe with the timing of all the gestures, and a `stages` dataframe with the timing of the different experimental stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3ae0c-ca65-463c-a6c1-264236ad7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"task:            \", data.task)\n",
    "print(\"emg shape:       \", data.emg.shape)\n",
    "print(\"timestamp shape: \", data.time.shape)\n",
    "print(\"stages:\")\n",
    "display(data.stages.head())\n",
    "print(\"prompts:\")\n",
    "display(data.prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dface053-f8c0-4699-93d1-14139bb4025f",
   "metadata": {},
   "source": [
    "Data are similarly structured for the `handwriting` datasets. However, the dataframe now encodes the start and end times of each text prompt. Right and left arrows correspond to finger movements to the right and left that are used as spaces and backspaces, respectively (see paper for details). The hand emoji indicates a finger pinch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc841560-0bca-462b-91ac-ad9bfacb9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = get_task_dataset_paths(\"handwriting\")[0]\n",
    "data = load_data(file)\n",
    "\n",
    "print(\"task:            \", data.task)\n",
    "print(\"emg shape:       \", data.emg.shape)\n",
    "print(\"timestamp shape: \", data.time.shape)\n",
    "print(\"stages:\")\n",
    "display(data.stages.head())\n",
    "print(\"prompts:\")\n",
    "display(data.prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be18fd23-d25a-4679-8dea-c33d7f8fd88e",
   "metadata": {},
   "source": [
    "The `wrist` datasets do not have a `prompts` dataframe. Instead, they have an additional stream of `wrist_angles` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60414a80-7c1c-410e-bc04-db38591dbf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = get_task_dataset_paths(\"wrist\")[0]\n",
    "data = load_data(file)\n",
    "\n",
    "print(\"task:               \", data.task)\n",
    "print(\"emg shape:          \", data.emg.shape)\n",
    "print(\"wrist_angles shape: \", data.wrist_angles.shape)\n",
    "print(\"timestamp shape:    \", data.time.shape)\n",
    "print(\"stages:\")\n",
    "display(data.stages.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec1005e-baa3-4f4d-992a-35688a96ab7a",
   "metadata": {},
   "source": [
    "# Plotting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d7940c-cac8-4b7a-a801-61003e8b9374",
   "metadata": {},
   "source": [
    "## Discrete Gestures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aee266b-f69d-4e23-b03b-22a7a9d36574",
   "metadata": {},
   "source": [
    "Here we plot EMG snippets for a single `discrete_gestures` dataset in 1 second windows centered on different gesture types.\n",
    "\n",
    "Notice the use of `gesture_data.partition(start_time, end_time)` to extract windows of EMG around events of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04243946-1d5f-41c0-8bb7-f073b6040f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_file = get_task_dataset_paths(\"discrete_gestures\")[0]\n",
    "gesture_data = load_data(gesture_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3176825-3f47-4b58-8b7c-c0e38a81e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = [-.5, .5]\n",
    "nrows = 3\n",
    "ncols = 4\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(ncols * 3, nrows * 4))\n",
    "\n",
    "# Sample random gestures\n",
    "gestures = gesture_data.prompts.sample(nrows * ncols, random_state=2, replace=False)\n",
    "\n",
    "for ax, (_, gesture) in zip(axs.flatten(), gestures.iterrows()):\n",
    "    timeseries = gesture_data.partition(gesture.time + window[0], gesture.time + window[1])\n",
    "    plot_emg(timeseries[\"time\"], timeseries[\"emg\"], ax=ax)\n",
    "    gesture_name = gesture.loc[\"name\"]\n",
    "    ax.set(title=f\"{gesture_name}\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea70784-d9b8-4e57-8a79-8c3f6a999671",
   "metadata": {},
   "source": [
    "## Handwriting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd48994a-8c9d-492f-8125-56ff72b19157",
   "metadata": {},
   "source": [
    "Now we plot snippets of `handwriting` EMG corresponding to individual text prompts. Each snippet begins when the prompt first appears, and ends when the participant finishes writing the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5907bd01-ebb1-420f-ab11-7f4659ec5d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "handwriting_file = get_task_dataset_paths(\"handwriting\")[1]\n",
    "handwriting_data = load_data(handwriting_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dd392f-5ca8-41e3-b2e3-420de9000195",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 3\n",
    "ncols = 4\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(ncols * 3, nrows * 4))\n",
    "\n",
    "# Sample random prompts\n",
    "prompts = handwriting_data.prompts.sample(nrows * ncols, random_state=0, replace=False)\n",
    "\n",
    "for ax, (_, prompt) in zip(axs.flatten(), prompts.iterrows()):\n",
    "    timeseries = handwriting_data.partition(prompt.start, prompt.end)\n",
    "    plot_emg(timeseries[\"time\"], timeseries[\"emg\"], ax=ax)\n",
    "    ax.set(title=f\"{prompt.prompt}\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be1dcd5-d49f-4055-b702-67ed88207695",
   "metadata": {},
   "source": [
    "## Wrist angles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91c96a1-9a90-41de-9364-38d15d5cf521",
   "metadata": {},
   "source": [
    "Finally, we'll plot EMG and wrist angles side-by-side for a few example stages from a `wrist` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870e052-c0ed-4e30-8c03-1751d5ad5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrist_file = get_task_dataset_paths(\"wrist\")[0]\n",
    "wrist_data = load_data(wrist_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e9944-f3ad-491a-833b-5ad3af55192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stages = 3\n",
    "\n",
    "# Sample random stages\n",
    "stages = wrist_data.stages.sample(num_stages, random_state=0, replace=False)\n",
    "\n",
    "for _, stage in stages.iterrows():\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 8), gridspec_kw={\"height_ratios\": [1, 6]})\n",
    "    timeseries = wrist_data.partition(stage.start, stage.end)\n",
    "\n",
    "    plot_wrist(timeseries[\"time\"], timeseries[\"wrist_angles\"], ax=axs[0])\n",
    "    plot_emg(timeseries[\"time\"], timeseries[\"emg\"], ax=axs[1])\n",
    "\n",
    "    fig.suptitle(f\"{os.path.basename(wrist_file)}\\nStage {stage['name']}\")\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
